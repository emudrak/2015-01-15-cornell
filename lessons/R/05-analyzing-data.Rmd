---
layout: topic
title: Analyzing and Plotting Data
minutes: 60
---

```{r, echo=FALSE, purl=FALSE}
knitr::opts_chunk$set(results='hide', fig.path='img/r-lesson-', comment=NA)
surveys <- read.csv(file="../../data/biology/surveys.csv")
```

> ## Learning Objectives
>
> * understand how to deal with missing data
> * being able to generate summary statistics from the data
> * calculate basic statistics across a levels of a factor (here species)
> * generate plot from the data using the average weights of the animals as an
>   example


# Calculating statistics

Let's get a closer look at our data. For instance, we might want to know how
many animals we trapped in each plot, or how many of each species were caught.

To get a `vector` of all the species, we are going to use the `unique()`
function that tells us the unique values in a given vector:

```{r, purl=FALSE}
unique(surveys$species)
```

The function `table()`, tells us how many of each species we have:

```{r, purl=FALSE}
table(surveys$species)
```

R has a lot of built in statistical functions, like `mean()`, `median()`,
`max()`, `min()`, `var()`, `sd()`. Let's start by calculating the average weight of all the
animals using the function `mean()`:

```{r, results='show', purl=FALSE}
mean(surveys$wgt)
```

Hmm, we just get `NA`. That's because we don't have the weight for every animal
and missing data is recorded as `NA`. By default, all R functions operating on a
vector that contains missing data will return NA. It's a way to make sure that
users know they have missing data, and make a conscious decision on how to deal
with it.

When dealing with simple statistics like the mean, the easiest way to ignore
`NA` (the missing data) is to use `na.rm=TRUE` (`rm` stands for remove):

```{r, results='show', purl=FALSE}
mean(surveys$wgt, na.rm=TRUE)
```

In some cases, it might be useful to remove the missing data from the
vector. For this purpose, R comes with the function `na.omit`:

```{r, purl=FALSE}
wgt_noNA <- na.omit(surveys$wgt)
```

For some applications, it's useful to keep all observations, for others, it
might be best to remove all observations that contain missing data. The function
`complete.cases()` removes any rows that contain at least one missing
observation:

```{r, purl=FALSE}
surveys_complete <- surveys[complete.cases(surveys), ]

```

The new data.frame `surveys_complete` now has only complete data.  Lets see how many observations of each species was retained: 


```{r, purl=FALSE}
table(surveys_complete$species)
```
Many species have 0 values in this table, meaning there are no records of this species left (i.e. none had the weight recorded).  Yet they still show up in this table. This is because R "remembers" all species that were found in the
original dataset, even though they aren't included in this data set.  This could get annoying later on (with plotting, etc...). 

To remove the `NA` and make things clearer, we can redefine the levels for the factor "species" by re-establishing this as a factor. 

```{r, purl=FALSE}
surveys_complete$species <- factor(surveys_complete$species)

```
An equivalent way to do this is to us the droplevels() function. This will work if you have many columns from the same data frame that need excess factors removed. 

```{r}
surveys_complete <- droplevels(surveys_complete)
```

Now see how things are looking: 

```{r}
table(surveys_complete$species)
```


## PAUSE ##
Make sure everyone has a clean copy of surveys_complete. 

If you have been lost/confused/in the bathroom, you can catch up now with: 

```{r}
##CLEAR WORKPACE????

#surveys <- read.csv('data/surveys.csv')
surveys$logwgt <- log(surveys$wgt)
surveys$plot <- as.factor(surveys$plot)
surveys_complete <- surveys[complete.cases(surveys), ]
surveys_complete <- droplevels(surveys_complete)


```



### Challenge

1. To determine the number of elements found in a vector, we can use
use the function `length()` (e.g., `length(surveys$wgt)`). Using `length()`, how
many animals have not had their weights recorded?

1. What is the range (minimum and maximum) weight?

1. What is the median weight for the males?

1. Bonus question: what is the standard error for the weight? (hints: there is
   no built-in function to compute standard errors, and the function for the
   square root is `sqrt()`).

```{r, echo=FALSE, purl=TRUE}
## 1. To determine the number of elements found in a vector, we can use
## use the function `length()` (e.g., `length(surveys$wgt)`). Using `length()`, how
## many animals have not had their weights recorded?
length(surveys$wgt)-length(wgt_noNA)
summary(surveys$wgt)


## 2. What is the range (minimum and maximum) weight?
min(surveys$wgt, na.rm=TRUE)
max(surveys$wgt, na.rm=T)
range(surveys$wgt, na.rm=T)

min(surveys_complete$wgt)
max(surveys_complete$wgt)
range(surveys_complete$wgt)

## 3. What is the median weight for the males?
median(subset(surveys, sex="M")$wgt, na.rm=T)
median(subset(surveys_complete, sex="M")$wgt)

```

# Statistics across factor levels

What if we want the maximum weight for each species, or the mean for each
plot?

R comes with convenient functions to do this kind of operations, functions in
the `apply` family.

For instance, `tapply()` allows us to repeat a function across each level of a
factor. The format is: 

`tapply(columns_to_do_the_calculations_on, factor_to_sort_on, function)`

If we want to calculate the maximum for each species (using the complete dataset):

```{r, purl=FALSE}
tapply(surveys_complete$wgt, surveys_complete$species, max)
```

If we want to calculate the mean for each plot:

```{r, purl=FALSE}
tapply(surveys_complete$wgt, surveys_complete$plot, mean)
```

<!--- Can we skip this, or do we need to use this later? 
### Challenge

1. Create new objects to store: the standard deviation, the maximum and minimum
   values for the weight of each species
1. How many species do you have these statistics for?
1. Create a new data frame (called `surveys_summary`) that contains as columns:
   * `species` the 2 letter code for the species names
   * `mean_wgt` the mean weight for each species
   * `sd_wgt` the standard deviation for each species
   * `min_wgt`  the minimum weight for each species
   * `max_wgt`  the maximum weight for each species

```{r, echo=FALSE, purl=TRUE}
## 1. Create new objects to store: the standard deviation, the maximum and minimum
##    values for the weight of each species
## 2. How many species do you have these statistics for?
## 3. Create a new data frame (called `surveys_summary`) that contains as columns:
##    * `species` the 2 letter code for the species names
##    * `mean_wgt` the mean weight for each species
##    * `sd_wgt` the standard deviation for each species
##    * `min_wgt`  the minimum weight for each species
##    * `max_wgt`  the maximum weight for each species
```

**Answers**

```{r, purl=FALSE}
species_max <- tapply(surveys_complete$wgt, surveys_complete$species, max)
species_min <- tapply(surveys_complete$wgt, surveys_complete$species, min)
species_mean <- tapply(surveys_complete$wgt, surveys_complete$species, min)
species_sd <- tapply(surveys_complete$wgt, surveys_complete$species, sd)
nlevels(surveys_complete$species) # or length(species_mean)
surveys_summary <- data.frame(species=levels(surveys_complete$species),
                              mean_wgt=species_mean,
                              sd_wgt=species_sd,
                              min_wgt=species_min,
                              max_wgt=species_max)
```


---> 
```{r, echo=FALSE, purl=TRUE}
## Plotting
```

# Creating a barplot

The mathematician Richard Hamming once said, "The purpose of computing is
insight, not numbers", and the best way to develop insight is often to visualize
data. Visualization deserves an entire lecture (or course) of its own, but we
can explore a few features of R's base plotting package.

Let's use the `surveys_summary` data that we generated and plot it.

R has built in plotting functions.

```{r, purl=FALSE}
barplot(table(surveys_complete$species))
```

The axis labels are too big though, so you can't see them all. Let's change that.

```{r, purl=FALSE}
barplot(surveys_summary$mean_wgt, cex.names=0.4)
```

Alternatively, we may want to flip the axes to have more room for the species names:

```{r, purl=FALSE}
barplot(surveys_summary$mean_wgt, horiz=TRUE, las=1, cex.names=0.6)
```

Let's also add some colors, and add a main title, label the axis:

```{r, purl=FALSE}
barplot(surveys_summary$mean_wgt, horiz=TRUE, las=1,
        col=c("lavender", "lightblue"), xlab="Weight (g)",
        main="Mean weight per species")
```

### Challenge

1. Create a new plot showing the standard deviation for each species. Choose
   one or more colors from
   [here](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf). (If you
   prefer, you can also specify colors using their hexadecimal values
   `#RRGGBB`.)

```{r, echo=FALSE, purl=TRUE}
## 1. Create a new plot showing the standard deviation for each species.
```

## More about plotting

There are lots of different ways to plot things. You can do `plot(object)` for
most classes included in R base. To explore some of the possibilities:

```{r, eval=FALSE, purl=FALSE}
?barplot
?boxplot
?plot.default
example(barplot)
```



If you wanted to output this plot to a pdf file rather than to the screen, you
can specify where you want the plot to go with the `pdf()` function. If you
wanted it to be a JPG, you would use the function `jpeg()` (other formats
available: svg, png, ps).

Be sure to add `dev.off()` at the end to finalize the file. For `pdf()`, you can
create multiple pages to your file, by generating multiple plots before calling
`dev.off()`.


```{r, eval=FALSE, purl=TRUE}
pdf("mean_per_species.pdf")
barplot(surveys_summary$mean_wgt, horiz=TRUE, las=1,
        col=c("lavender", "lightblue"), xlab="Weight (g)",
        main="Mean weight per species")
dev.off()
```

#Inflammation Data

We are studying inflammation in patients who have been given a new treatment for arthritis,
and need to analyze the first dozen data sets. 
The data sets are stored in [comma-separated values](../../gloss.html#comma-separeted-values) (CSV) format: each row holds information for a single patient, and the columns represent successive days. 
The first few rows of our first file look like this:

```{r echo = FALSE}
tmp <- read.csv("../../data/inflammation/inflammation-01.csv", header = FALSE, nrows = 5)
write.table(tmp, quote = FALSE, sep = ",", row.names = FALSE, col.names = FALSE)
rm(tmp)
```

We want to:

* load that data into memory,
* calculate the average inflammation per day across all patients, and
* plot the result.

To do all that, we'll have to learn a little bit about programming.

#### Objectives

* Read tabular data from a file into a program.
* Assign values to variables.
* Select individual values and subsections from data.
* Perform operations on a data frame of data.
* Display simple graphs.

### Loading Data

To load our inflammation data, first we need to locate our data.
We can change the current working directory to the location of the CSV files using the function `setwd`.
For example, if the CSV files are located in a directory named `swc` in our home directory, we would change the working directory using the following command:

```{r, eval=FALSE}
setwd("~/swc")
```


Alternatively you can change the working directory using the RStudio GUI using the menu option `Session` -> `Set Working Directory` -> `Choose Directory...`

Now we could load the data into R using `read.csv`:

```{r, eval=FALSE}
read.csv(file = "inflammation-01.csv", header = FALSE)
```

The expression `read.csv(...)` is a [function call](../../gloss.html#function-call) that asks R to run the function `read.csv`. 

`read.csv` has two [arguments](../../gloss.html#argument): the name of the file we want to read, and whether the first line of the file contains names for the columns of data.
The filename needs to be a character string (or [string](../../gloss.html#string) for short), so we put it in quotes.
Assigning the second argument, `header`, to be `FALSE` indicates that the data file does not have column headers.

```{r }
dat <- read.csv(file="../../data/inflammation/inflammation-01.csv")
```



```{r, results="hide", eval=FALSE}
dat <- read.csv(file = "inflammation-01.csv", header = FALSE)

head(dat)
```


#### Challenge

* What class is this data?
* How many patients (rows) does this data contain?
* How many days (columns) do we have data for? 
* Whatt is the inflammation level for patients 30 at day 20? 



```{r answers, echo=FALSE}
class(dat)
nrow(dat)
ncol(dat)
dim(dat)
dat[30, 20]

```


Now let's perform some common mathematical operations to learn about our inflammation data.
When analyzing data we often want to look at partial statistics, such as the maximum value per patient or the average value per day. 
One way to do this is to select the data we want to create a new temporary data frame, and then perform the calculation on this subset:

```{r}
# first row, all of the columns
patient_1 <- dat[1, ]
# max inflammation for patient 1
max(patient_1)
```

We don't actually need to store the row in a variable of its own. 
Instead, we can combine the selection and the function call:

```{r}
# max inflammation for patient 2
max(dat[2, ])
```

R also has functions for other commons calculations, e.g. finding the minimum, mean, median, and standard deviation of the data:

#Challenge

* What is the minimum inflammation on day 7? 
* What is the mean inflammation on day 12? 
* What is the maximum inflammation for patient 5


```{r, echo=FALSE, results="hide"}
# minimum inflammation on day 7
min(dat[, 7])
# mean inflammation on day 7
mean(dat[, 12])
# max inflammation for patient 5
max(dat[5, ])

```

What if we need the maximum inflammation for all patients, or the average for each day?

To support this, we can use the `apply` function.

> **Tip:** To learn about a function in R, e.g. `apply`, we can read its help documention by running `help(apply)` or `?apply`.

`apply` allows us to repeat a function on all of the rows (`MARGIN = 1`) or columns (`MARGIN = 2`) of a data frame.

Thus, to obtain the average inflammation of each patient we will need to calculate the mean of all of the rows (`MARGIN = 1`) of the data frame.

```{r}
avg_patient_inflammation <- apply(dat, 1, mean)
```

And to obtain the average inflammation of each day we will need to calculate the mean of all of the columns (`MARGIN = 2`) of the data frame.

```{r}
avg_day_inflammation <- apply(dat, 2, mean)
```

Since the second argument to `apply` is `MARGIN`, the above command is equivalent to `apply(dat, MARGIN = 2, mean)`.
We'll learn why this is so in the next lesson.

> **Tip:** Some common operations have more efficient alternatives.
For example, you can calculate the row-wise or column-wise means with `rowMeans` and `colMeans`, respectively.

### Plotting

The mathematician Richard Hamming once said, "The purpose of computing is insight, not numbers," and the best way to develop insight is often to visualize data.
Visualization deserves an entire lecture (or course) of its own, but we can explore a few of R's plotting features. 

Let's take a look at the average inflammation over time.
Recall that we already calculated these values above using `apply(dat, 2, mean)` and saved them in the variable `avg_day_inflammation`.
Plotting the values is done with the function `plot`.

```{r plot-avg-inflammation}
plot(avg_day_inflammation)
plot(avg_day_inflammation, type="l")
```

Above, we gave the function `plot` a vector of numbers corresponding to the average inflammation per day across all patients.
`plot` created a scatter plot where the y-axis is the average inflammation level and the x-axis is the order, or index, of the values in the vector, which in this case correspond to the 40 days of treatment.
The result is roughly a linear rise and fall, which is suspicious: based on other studies, we expect a sharper rise and slower fall.
Let's have a look at two other statistics: the maximum and minimum inflammation per day.

```{r plot-max-inflammation}
max_day_inflammation <- apply(dat, 2, max)
plot(max_day_inflammation, type="l")
```

```{r plot-min-inflammation}
min_day_inflammation <- apply(dat, 2, min)
plot(min_day_inflammation, type="l")
```

The maximum value rises and falls perfectly smoothly, while the minimum seems to be a step function. Neither result seems particularly likely, so either there's a mistake in our calculations or something is wrong with our data.

*Note* you can show all of these plots together by modifying some R graphics parameters.  This is done with the command `par()`.  Look at the help file for this function either by typing it in the search window, or by typing `?par()`.  There are many, many parameters that can be adjusted here.  It is good practice to save the default values in the `par()` settings in an object, say `op` so you can return back to them later. 



```{r, warning=FALSE}
op <- par()
par(mfrow=c(1,3))
plot(avg_day_inflammation, type="l")
plot(max_day_inflammation, type="l")
plot(min_day_inflammation, type="l")
par(op)
```



#### Key Points

* Use `variable <- value` to assign a value to a variable in order to record it in memory.
* Objects are created on demand whenever a value is assigned to them.
* The function `dim` gives the dimensions of a data frame.
* Use `object[x, y]` to select a single element from a data frame.
* Use `from:to` to specify a sequence that includes the indices from `from` to `to`.
* All the indexing and slicing that works on data frames also works on vectors.
* Use `#` to add comments to programs.
* Use `mean`, `max`, `min` and `sd` to calculate simple statistics.
* Use `apply` to calculate statistics across the rows or columns of a data frame.
* Use `plot` to create simple visualizations.

#### Next Steps

Our work so far has convinced us that something's wrong with our first data file.
We would like to check the other 11 the same way, but typing in the same commands repeatedly is tedious and error-prone.
Since computers don't get bored (that we know of), we should create a way to do a complete analysis with a single command, and then figure out how to repeat that step once for each file.
These operations are the subjects of the next two lessons.


